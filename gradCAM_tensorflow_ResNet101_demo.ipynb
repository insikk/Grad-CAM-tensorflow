{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM Visualization Demo with ResNet101\n",
    "\n",
    "Requirement:\n",
    "\n",
    "* GPU Memory: 6GB or higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace vanila relu to guided relu to get guided backpropagation.\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naver/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9228a505b541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# Run tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_graph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# sess.run(tf.local_variables_initializer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/resnet50-fpn/tf1.3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \"\"\"\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/resnet50-fpn/tf1.3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    619\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewDeprecatedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/resnet50-fpn/tf1.3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nets import resnet_v1\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "# Create mini-batch for demo\n",
    "\n",
    "img1 = utils.load_image(\"./demo.png\", normalize=False)\n",
    "img2 = utils.load_image(\"./shihtzu_mypuppy.jpg\", normalize=False)\n",
    "img3 = utils.load_image(\"./tiger.jpg\", normalize=False)\n",
    "\n",
    "batch1_img = img1.reshape((1, 224, 224, 3))\n",
    "batch1_label = np.array([1 if i == 242 else 0 for i in range(1000)])  # 1-hot result for Boxer\n",
    "batch1_label = batch1_label.reshape(1, -1)\n",
    "\n",
    "batch2_img = img2.reshape((1, 224, 224, 3))\n",
    "batch2_label = np.array([1 if i == 155 else 0 for i in range(1000)])  # 1-hot result for Shih-Tzu\n",
    "batch2_label = batch2_label.reshape(1, -1)\n",
    "\n",
    "batch3_img = img3.reshape((1, 224, 224, 3))\n",
    "batch3_label = np.array([1 if i == 292 else 0 for i in range(1000)])  # 1-hot result for tiger\n",
    "batch3_label = batch3_label.reshape(1, -1)\n",
    "\n",
    "batch_img = np.concatenate((batch1_img, batch2_img, batch3_img), 0)\n",
    "batch_label = np.concatenate((batch1_label, batch2_label, batch3_label), 0)\n",
    "batch_size = 3\n",
    "\n",
    "# batch_img = np.concatenate((batch1_img), 0)\n",
    "# batch_label = np.concatenate((batch1_label), 0)\n",
    "# batch_size = 1\n",
    "# batch_label = batch_label.reshape(batch_size, -1)\n",
    "\n",
    "# Create tensorflow graph for evaluation\n",
    "eval_graph = tf.Graph()\n",
    "with eval_graph.as_default():\n",
    "    with eval_graph.gradient_override_map({'Relu': 'GuidedRelu'}):\n",
    "        images = tf.placeholder(\"float\", [batch_size, 224, 224, 3])\n",
    "        labels = tf.placeholder(tf.float32, [batch_size, 1000])\n",
    "        train_mode = tf.placeholder(tf.bool)\n",
    "        \n",
    "        preprocessed_images = utils.resnet_preprocess(images)\n",
    "        \n",
    "        with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "            net, end_points = resnet_v1.resnet_v1_101(preprocessed_images, 1000, is_training=train_mode)\n",
    "        prob = end_points['predictions'] # after softmax\n",
    "        \n",
    "        # sess_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.OFF\n",
    "        cost = tf.reduce_sum((prob - labels) ** 2)\n",
    "        train = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "\n",
    "        # Get last convolutional layer gradient for generating gradCAM visualization\n",
    "        # print('endpoints:', end_points.keys())\n",
    "        target_conv_layer = end_points['resnet_v1_101/block4/unit_2/bottleneck_v1']\n",
    "        # target_conv_layer = end_points['resnet_v1_50/block3/unit_5/bottleneck_v1']\n",
    "        target_conv_layer_grad = tf.gradients(cost, target_conv_layer)[0]\n",
    "\n",
    "        # Guided backpropagtion back to input layer\n",
    "        gb_grad = tf.gradients(cost, images)[0]\n",
    "\n",
    "        # Normalizing the gradients    \n",
    "        target_conv_layer_grad_norm = tf.div(target_conv_layer_grad, tf.sqrt(tf.reduce_mean(tf.square(target_conv_layer_grad))) + tf.constant(1e-5))\n",
    "\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        # Load resnet v1 weights\n",
    "        \n",
    "        # latest_checkpoint = tf.train.latest_checkpoint(\"model/resnet_v1_50.ckpt\")\n",
    "        latest_checkpoint = \"model/resnet_v1_101.ckpt\"\n",
    "        ## Optimistic restore.\n",
    "        reader = tf.train.NewCheckpointReader(latest_checkpoint)\n",
    "        saved_shapes = reader.get_variable_to_shape_map()\n",
    "        variables_to_restore = tf.global_variables()\n",
    "        for var in variables_to_restore:\n",
    "          if not var.name.split(':')[0] in saved_shapes:\n",
    "            print(\"WARNING. Saved weight not exists in checkpoint. Init var:\", var.name)\n",
    "          else:\n",
    "            # print(\"Load saved weight:\", var.name)\n",
    "            pass\n",
    "\n",
    "        var_names = sorted([(var.name, var.name.split(':')[0]) for var in variables_to_restore\n",
    "                if var.name.split(':')[0] in saved_shapes])\n",
    "        restore_vars = []\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            for var_name, saved_var_name in var_names:\n",
    "                try:\n",
    "                    curr_var = tf.get_variable(saved_var_name)\n",
    "                    var_shape = curr_var.get_shape().as_list()\n",
    "                    if var_shape == saved_shapes[saved_var_name]:\n",
    "                        # print(\"restore var:\", saved_var_name)\n",
    "                        restore_vars.append(curr_var)\n",
    "                except ValueError:\n",
    "                    print(\"Ignore due to ValueError on getting var:\", saved_var_name) \n",
    "        saver = tf.train.Saver(restore_vars)\n",
    "        \n",
    "        \n",
    "        \n",
    "# Run tensorflow \n",
    "\n",
    "with tf.Session(graph=eval_graph) as sess:    \n",
    "    sess.run(init)    \n",
    "    # sess.run(tf.local_variables_initializer())\n",
    "    saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    prob = sess.run(prob, feed_dict={images: batch_img, train_mode: False})  \n",
    "    \n",
    "    gb_grad_value, target_conv_layer_value, target_conv_layer_grad_value = sess.run([gb_grad, target_conv_layer, target_conv_layer_grad_norm], feed_dict={images: batch_img, labels: prob, train_mode: True})\n",
    "    # gb_grad_value, target_conv_layer_value, target_conv_layer_grad_value = sess.run([gb_grad, target_conv_layer, target_conv_layer_grad_norm], feed_dict={images: batch_img, labels: label, train_mode: True})\n",
    "    \n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # print('See visualization of below category')\n",
    "        # utils.print_prob(batch_label[i], './synset.txt')\n",
    "        utils.print_prob(prob[i], './synset.txt')\n",
    "        # print('gb_grad_value[i]:', gb_grad_value[i])\n",
    "        # print('gb_grad_value[i] shape:', gb_grad_value[i].shape)\n",
    "        utils.visualize(batch_img[i], target_conv_layer_value[i], target_conv_layer_grad_value[i], gb_grad_value[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.3",
   "language": "python",
   "name": "tf1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
